{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>hb</th>\n",
       "      <th>pcv</th>\n",
       "      <th>rbc</th>\n",
       "      <th>mcv</th>\n",
       "      <th>mch</th>\n",
       "      <th>mchc</th>\n",
       "      <th>rdw</th>\n",
       "      <th>wbc</th>\n",
       "      <th>neut</th>\n",
       "      <th>lymph</th>\n",
       "      <th>plt</th>\n",
       "      <th>hba</th>\n",
       "      <th>hba2</th>\n",
       "      <th>hbf</th>\n",
       "      <th>phenotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>35.2</td>\n",
       "      <td>5.12</td>\n",
       "      <td>68.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>53.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>309.0</td>\n",
       "      <td>88.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>26.6</td>\n",
       "      <td>4.28</td>\n",
       "      <td>62.1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>40.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>10.3</td>\n",
       "      <td>49.40</td>\n",
       "      <td>43.10</td>\n",
       "      <td>687.0</td>\n",
       "      <td>87.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>35.2</td>\n",
       "      <td>5.12</td>\n",
       "      <td>68.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>53.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>309.0</td>\n",
       "      <td>88.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>5.17</td>\n",
       "      <td>84.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>31.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>334.0</td>\n",
       "      <td>86.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>5.02</td>\n",
       "      <td>68.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>33.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>67.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>596.0</td>\n",
       "      <td>86.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>5.19</td>\n",
       "      <td>88.4</td>\n",
       "      <td>29.9</td>\n",
       "      <td>33.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>47.57</td>\n",
       "      <td>40.98</td>\n",
       "      <td>177.0</td>\n",
       "      <td>88.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>4.93</td>\n",
       "      <td>67.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>31.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>44.50</td>\n",
       "      <td>45.50</td>\n",
       "      <td>295.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>29.8</td>\n",
       "      <td>4.75</td>\n",
       "      <td>62.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>48.20</td>\n",
       "      <td>41.50</td>\n",
       "      <td>262.0</td>\n",
       "      <td>85.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>37.2</td>\n",
       "      <td>5.43</td>\n",
       "      <td>68.5</td>\n",
       "      <td>20.6</td>\n",
       "      <td>30.1</td>\n",
       "      <td>15.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>76.80</td>\n",
       "      <td>277.0</td>\n",
       "      <td>86.52</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>44.5</td>\n",
       "      <td>5.70</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>36.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>86.52</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex    hb   pcv   rbc   mcv   mch  mchc   rdw   wbc   neut  lymph    plt  \\\n",
       "0      1  10.8  35.2  5.12  68.7  21.2  30.8  13.4   9.6  53.00  33.00  309.0   \n",
       "1      0  10.8  26.6  4.28  62.1  25.3  40.8  19.8  10.3  49.40  43.10  687.0   \n",
       "2      1  10.8  35.2  5.12  68.7  21.2  30.8  13.4   9.6  53.00  33.00  309.0   \n",
       "3      0  14.5  43.5  5.17  84.0  28.0  33.4  12.1  11.9  31.00  50.00  334.0   \n",
       "4      0  11.5  34.4  5.02  68.7  22.9  33.4  15.7  20.4  67.00  30.00  596.0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...   \n",
       "198    0  15.5  45.9  5.19  88.4  29.9  33.8  12.6   8.8  47.57  40.98  177.0   \n",
       "199    1  10.4  33.3  4.93  67.6  21.1  31.2  14.8   8.9  44.50  45.50  295.0   \n",
       "200    0   9.8  29.8  4.75  62.7  19.0  30.4  14.7   7.2  48.20  41.50  262.0   \n",
       "201    0  11.2  37.2  5.43  68.5  20.6  30.1  15.1  12.0  13.50  76.80  277.0   \n",
       "202    0  14.4  44.5  5.70  78.0  25.3  31.2  15.0   7.2  36.00  59.00  224.0   \n",
       "\n",
       "       hba  hba2   hbf  phenotype  \n",
       "0    88.50  2.60  0.11          1  \n",
       "1    87.80  2.40  0.90          1  \n",
       "2    88.50  2.60  0.10          1  \n",
       "3    86.80  2.80  0.30          1  \n",
       "4    86.30  2.40  1.30          1  \n",
       "..     ...   ...   ...        ...  \n",
       "198  88.60  3.20  0.40          0  \n",
       "199  88.00  2.40  0.50          0  \n",
       "200  85.10  2.40  1.10          0  \n",
       "201  86.52  2.59  0.77          0  \n",
       "202  86.52  2.59  0.77          0  \n",
       "\n",
       "[203 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Alpha-Thalassemia.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='phenotype',data=dataset,palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (142, 15)\n",
      "X_test shape: (61, 15)\n",
      "Y_train shape: (142,)\n",
      "Y_test shape: (61,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]].values\n",
    "y = dataset.iloc[:, 15].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify = y, random_state = 0)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", y_train.shape)\n",
    "print(\"Y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>hb</th>\n",
       "      <th>pcv</th>\n",
       "      <th>rbc</th>\n",
       "      <th>mcv</th>\n",
       "      <th>mch</th>\n",
       "      <th>mchc</th>\n",
       "      <th>rdw</th>\n",
       "      <th>wbc</th>\n",
       "      <th>neut</th>\n",
       "      <th>lymph</th>\n",
       "      <th>plt</th>\n",
       "      <th>hba</th>\n",
       "      <th>hba2</th>\n",
       "      <th>hbf</th>\n",
       "      <th>phenotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>40.6</td>\n",
       "      <td>5.80</td>\n",
       "      <td>91.6</td>\n",
       "      <td>24.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>47.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>275.5</td>\n",
       "      <td>85.80</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>45.3</td>\n",
       "      <td>4.95</td>\n",
       "      <td>80.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>14.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>66.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>236.0</td>\n",
       "      <td>84.70</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>83.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>208.0</td>\n",
       "      <td>87.70</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.6</td>\n",
       "      <td>5.56</td>\n",
       "      <td>82.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>84.86</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>43.6</td>\n",
       "      <td>5.05</td>\n",
       "      <td>86.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>52.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>87.10</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>4.05</td>\n",
       "      <td>79.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>31.7</td>\n",
       "      <td>16.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>39.1</td>\n",
       "      <td>4.98</td>\n",
       "      <td>69.5</td>\n",
       "      <td>22.9</td>\n",
       "      <td>32.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>38.6</td>\n",
       "      <td>50.3</td>\n",
       "      <td>392.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>5.17</td>\n",
       "      <td>84.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>86.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>41.2</td>\n",
       "      <td>5.22</td>\n",
       "      <td>78.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>44.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>256.0</td>\n",
       "      <td>89.20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>6.02</td>\n",
       "      <td>68.3</td>\n",
       "      <td>20.9</td>\n",
       "      <td>30.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>86.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex    hb   pcv   rbc   mcv   mch  mchc   rdw   wbc  neut  lymph    plt  \\\n",
       "0   0.0  14.1  40.6  5.80  91.6  24.3  33.4  13.6   8.9  47.6   41.0  275.5   \n",
       "1   0.0  13.9  45.3  4.95  80.7  18.6  30.7  14.9   7.3  66.2   28.5  236.0   \n",
       "2   0.0  12.5  38.0  4.55  83.4  27.4  32.9  13.4   9.5  44.5   45.5  208.0   \n",
       "3   0.0  14.3  45.6  5.56  82.0  25.7  31.3  15.3  15.5  50.0   45.0  254.0   \n",
       "4   0.0  13.7  43.6  5.05  86.3  27.1  31.4  14.2  12.4  52.8   36.0  296.0   \n",
       "..  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...    ...   \n",
       "56  1.0  10.2  32.1  4.05  79.3  25.1  31.7  16.1  10.2  72.0   21.0  248.0   \n",
       "57  0.0  11.4  39.1  4.98  69.5  22.9  32.9  16.0  12.5  38.6   50.3  392.0   \n",
       "58  0.0  14.5  43.5  5.17  84.0  28.0  33.4  12.1  11.9  31.0   50.0  334.0   \n",
       "59  1.0  13.6  41.2  5.22  78.9  26.1  33.0  14.5   5.8  44.5   45.5  256.0   \n",
       "60  1.0  12.6  37.8  6.02  68.3  20.9  30.7  14.3   8.7  60.0   29.0  432.0   \n",
       "\n",
       "      hba  hba2   hbf  phenotype  \n",
       "0   85.80  2.60  1.00          1  \n",
       "1   84.70  2.90  0.50          1  \n",
       "2   87.70  2.50  0.20          1  \n",
       "3   84.86  2.68  0.54          0  \n",
       "4   87.10  2.60  0.30          1  \n",
       "..    ...   ...   ...        ...  \n",
       "56  90.00  2.20  0.60          1  \n",
       "57  88.00  2.20  0.40          1  \n",
       "58  86.80  2.80  0.30          1  \n",
       "59  89.20  2.80  0.30          1  \n",
       "60  86.90  2.80  0.20          0  \n",
       "\n",
       "[61 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xgeneric = pd.DataFrame(X_test)\n",
    "ygeneric = pd.DataFrame(y_test)\n",
    "data_baru = pd.concat([Xgeneric, ygeneric],  axis=1)\n",
    "data_baru.columns = ['sex', 'hb', 'pcv','rbc', 'mcv', 'mch', 'mchc', 'rdw', 'wbc',\n",
    "                     'neut', 'lymph', 'plt', 'hba', 'hba2', 'hbf', 'phenotype']\n",
    "data_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    104\n",
       "0     38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    44\n",
       "0    17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(y_train)\n",
    "X_mayor = []\n",
    "X_minor = []\n",
    "y_mayor =[]\n",
    "y_minor =[]\n",
    "n = len(arr)\n",
    "\n",
    "for i in range (len(arr)):\n",
    "    if arr[i] == 1:\n",
    "        X_mayor.append(np.array(X_train[i:i+1]))\n",
    "        y_mayor.append(np.array(arr[i]))\n",
    "    else:\n",
    "        X_minor.append(np.array(X_train[i:i+1]))\n",
    "        y_minor.append(np.array(arr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(X_train)\n",
    "Xmayor = []\n",
    "ymayor = []\n",
    "for i in range (len(X_mayor)):\n",
    "        Xmayor.append(X_mayor[i][0])\n",
    "        ymayor.append(y_mayor[i])\n",
    "# # Xmayor\n",
    "arr = np.array(X_train)\n",
    "Xminor =[]\n",
    "yminor =[]\n",
    "for i in range (len(X_minor)):\n",
    "        Xminor.append(X_minor[i][0])\n",
    "        yminor.append(y_minor[i])\n",
    "# Xminor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataminorX = pd.DataFrame(Xminor)\n",
    "# dataminorX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataminory =  pd.DataFrame(yminor)\n",
    "# dataminory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclidean_distance(data_minor1, data_minor2):\n",
    "    temp = 0\n",
    "    for i in range (len(data_minor1)):\n",
    "        euc = (data_minor1[i]-data_minor2[i])**2\n",
    "        temp = temp+euc\n",
    "    return (math.sqrt(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diss(j):\n",
    "    dis_i = []\n",
    "    for i in range (len(Xminor)):\n",
    "        dis_i.append(euclidean_distance(Xminor[i],Xminor[j]))\n",
    "    return dis_i\n",
    "\n",
    "dis = []\n",
    "for i in range (len(Xminor)):\n",
    "    dis.append(diss(i))\n",
    "jarak = pd.DataFrame(dis)\n",
    "# jarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr3 = []\n",
    "k = 11\n",
    "for i in range (len(dis)):\n",
    "    arr2 = np.argsort(dis[i])\n",
    "    arr3.append(arr2[1:k])\n",
    "\n",
    "nCreate = len(Xmayor)-len(Xminor)\n",
    "# print(nCreate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counter = 1\n",
    "Xdata_generic = []\n",
    "ydata_generic = []\n",
    "\n",
    "while counter <= nCreate:\n",
    "    for i in range (len(Xminor)):\n",
    "        if counter <= nCreate:\n",
    "            datarandom = np.random.choice(arr3[i])\n",
    "            counter = counter+1\n",
    "            datasync = Xminor[i]+(Xminor[datarandom]-Xminor[i])*0.2\n",
    "            Xdata_generic.append(datasync)\n",
    "            ydata_generic.append(np.array(yminor[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xgeneric = pd.DataFrame(Xdata_generic)\n",
    "ygeneric = pd.DataFrame(ydata_generic)\n",
    "data_baru = pd.concat([Xgeneric, ygeneric],  axis=1)\n",
    "data_baru.columns = ['sex', 'hb', 'pcv','rbc', 'mcv', 'mch', 'mchc', 'rdw', 'wbc',\n",
    "                     'neut', 'lymph', 'plt', 'hba', 'hba2', 'hbf', 'phenotype']\n",
    "data_baru.loc[(data_baru.sex < 0.5), 'sex'] = 0\n",
    "data_baru.loc[(data_baru.sex >= 0.5), 'sex'] = 1\n",
    "\n",
    "# pd.reset_option('^display.', silent=True)\n",
    "# data_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataminorX = pd.DataFrame(Xminor)\n",
    "dataminory =  pd.DataFrame(yminor)\n",
    "data_Xmayor = pd.DataFrame(Xmayor)\n",
    "data_ymayor =  pd.DataFrame(ymayor)\n",
    "datamayor = pd.concat([data_Xmayor, data_ymayor],  axis=1)\n",
    "datamayor.columns = ['sex', 'hb', 'pcv','rbc', 'mcv', 'mch', 'mchc', 'rdw', 'wbc',\n",
    "                     'neut', 'lymph', 'plt', 'hba', 'hba2', 'hbf', 'phenotype']\n",
    "data_minor = pd.concat([dataminorX, dataminory],  axis = 1)\n",
    "data_minor.columns = ['sex', 'hb', 'pcv','rbc', 'mcv', 'mch', 'mchc', 'rdw', 'wbc',\n",
    "                     'neut', 'lymph', 'plt', 'hba', 'hba2', 'hbf', 'phenotype']\n",
    "dataminor_baru = pd.concat([data_minor, data_baru], ignore_index = True)\n",
    "data_train_sm = pd.concat([datamayor, dataminor_baru], ignore_index=True)\n",
    "# data_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_smote shape: (208, 15)\n",
      "Y_train_smote shape: (208,)\n"
     ]
    }
   ],
   "source": [
    "X_sm = data_train_sm.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]].values\n",
    "y_sm = data_train_sm.iloc[:, 15].values\n",
    "\n",
    "X_train_sm = X_sm\n",
    "y_train_sm = y_sm\n",
    "print(\"X_train_smote shape:\", X_train_sm.shape)\n",
    "print(\"Y_train_smote shape:\", y_train_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNBClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def separate_classes(self, X, y):\n",
    "        separated_classes = {}\n",
    "        for i in range(len(X)):\n",
    "            feature_values = X[i]\n",
    "            class_name = y[i]\n",
    "            if class_name not in separated_classes:\n",
    "                separated_classes[class_name] = []\n",
    "            separated_classes[class_name].append(feature_values)\n",
    "        return separated_classes\n",
    "\n",
    "    def summarize(self, X):\n",
    "        for feature in zip(*X):\n",
    "            yield {\n",
    "                'mean' : np.mean(feature),\n",
    "                'stdev' : np.std(feature)\n",
    "                \n",
    "            }\n",
    "\n",
    "    def gauss_distribution_function(self, x, mean, stdev):\n",
    "        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))\n",
    "        return exponent / (np.sqrt(2*np.pi)*stdev)\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "#         data = []\n",
    "        separated_classes = self.separate_classes(X, y)\n",
    "#         print(\"separated_classes\",separated_classes)\n",
    "        self.class_summary = {}\n",
    "        for class_name, feature_values in separated_classes.items():\n",
    "            self.class_summary[class_name] = {\n",
    "                'prior_proba': len(feature_values)/len(X),\n",
    "                'summary': [i for i in self.summarize(feature_values)],\n",
    "            } \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        MAPs = []\n",
    "        for row in X:\n",
    "            joint_proba = {}\n",
    "            for class_name, features in self.class_summary.items():\n",
    "                total_features = len(features['summary'])\n",
    "                likelihood = 1\n",
    "                for idx in range(total_features):\n",
    "                    feature = row[idx]\n",
    "                    mean = features['summary'][idx]['mean']\n",
    "                    stdev = features['summary'][idx]['stdev']\n",
    "                    normal_proba = self.gauss_distribution_function(feature, \\\n",
    "                    mean, stdev)\n",
    "                    likelihood *= normal_proba\n",
    "                prior_proba = features['prior_proba']\n",
    "                joint_proba[class_name] = prior_proba * likelihood\n",
    "            MAP = max(joint_proba, key=joint_proba.get)\n",
    "            MAPs.append(MAP)\n",
    "        return MAPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil klasifikasi Gaussian Naive Bayes pada Data Test:\n",
      "[[ 7 10]\n",
      " [11 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.41      0.40        17\n",
      "           1       0.77      0.75      0.76        44\n",
      "\n",
      "    accuracy                           0.66        61\n",
      "   macro avg       0.58      0.58      0.58        61\n",
      "weighted avg       0.66      0.66      0.66        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Hasil klasifikasi Gaussian Naive Bayes pada Data Test:\")\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print(\"Hasil klasifikasi Gaussian Naive Bayes pada Data Train:\")\n",
    "# print(confusion_matrix(y_train, train_pred)) \n",
    "# print(classification_report(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil klasifikasi Gaussian Naive Bayes pada Data Test:\n",
      "[[ 8  9]\n",
      " [23 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.47      0.33        17\n",
      "           1       0.70      0.48      0.57        44\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.48      0.47      0.45        61\n",
      "weighted avg       0.58      0.48      0.50        61\n",
      "\n",
      "Hasil klasifikasi Gaussian Naive Bayes pada Data Train:\n",
      "[[84 20]\n",
      " [50 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.81      0.71       104\n",
      "           1       0.73      0.52      0.61       104\n",
      "\n",
      "    accuracy                           0.66       208\n",
      "   macro avg       0.68      0.66      0.66       208\n",
      "weighted avg       0.68      0.66      0.66       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNBClassifier()\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "train_pred_sm = model.predict(X_train_sm)\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(\"Hasil klasifikasi Gaussian Naive Bayes pada Data Test:\")\n",
    "print(confusion_matrix(y_test, y_pred2)) \n",
    "print(classification_report(y_test, y_pred2))\n",
    "\n",
    "print(\"Hasil klasifikasi Gaussian Naive Bayes pada Data Train:\")\n",
    "print(confusion_matrix(y_train_sm, train_pred_sm)) \n",
    "print(classification_report(y_train_sm, train_pred_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
